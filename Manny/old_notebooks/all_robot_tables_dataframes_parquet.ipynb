{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e529cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from acquire import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a58d72c",
   "metadata": {},
   "source": [
    "### All Season & Robot Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9224fe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the JSON file with all season & robot links\n",
    "robot_links_dict = load_from_json(\"all_season_robot_links.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae5402e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_links = sum(len(links) for links in robot_links_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dec3f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394\n"
     ]
    }
   ],
   "source": [
    "print(total_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991c1e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the current index from file, or start from the beginning\n",
    "try:\n",
    "    with open('current_index.txt', 'r') as f:\n",
    "        current_index = int(f.read())\n",
    "except:\n",
    "    current_index = 0\n",
    "\n",
    "# Iterate through the dictionary of links starting from the current index\n",
    "for i, (season, links) in enumerate(robot_links_dict.items()):\n",
    "    if i < current_index:\n",
    "        continue\n",
    "    for link in links:\n",
    "        # Extract robot name from the link\n",
    "        robot_name = link.split('/')[-2]\n",
    "\n",
    "        # Send link to scraper browser\n",
    "        driver.get(link)\n",
    "\n",
    "        # Get rid of cookies_popup\n",
    "        #get_rid_of_cookies_popup(driver)\n",
    "\n",
    "        # Get table elements\n",
    "        div_element = driver.find_element_by_css_selector(\".grid-1-1.last\")\n",
    "        table_elements = div_element.find_elements_by_css_selector(\"table\")\n",
    "\n",
    "        # Check if there are two tables\n",
    "        if len(table_elements) == 2:\n",
    "            stats_history_html = table_elements[0].get_attribute(\"outerHTML\")\n",
    "            match_history_html = table_elements[1].get_attribute(\"outerHTML\")\n",
    "\n",
    "            # Create dataframes from the tables\n",
    "            stats_df = pd.read_html(stats_history_html)[0]\n",
    "            match_history_df = pd.read_html(match_history_html)[0]\n",
    "\n",
    "            # Save the dataframes to file\n",
    "            stats_df.to_pickle(f'{robot_name}_stats.pkl')\n",
    "            match_history_df.to_pickle(f'{robot_name}_match_history.pkl')\n",
    "        \n",
    "        # Sleep for a random amount of time between 3 and 7 seconds\n",
    "        time.sleep(random.uniform(1, 5))\n",
    "        \n",
    "    # Increment the current index and save to file\n",
    "    current_index += 1\n",
    "    with open('current_index.txt', 'w') as f:\n",
    "        f.write(str(current_index))\n",
    "        \n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b90d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('robot_data_captain-shredderator-wcvii.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977e63ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read nested dataframe from Parquet file\n",
    "pf = fp.ParquetFile('robot_data.parquet')\n",
    "df = pf.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62653130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the 'stats' dataframe for robot 'robot1'\n",
    "stats_df = df.loc['robot1', 'stats']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
